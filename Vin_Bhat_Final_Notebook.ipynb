{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Created by Vin Bhat (https://orcid.org/0009-0007-2302-0564) in collaboration with Marlin Wong, Neel Kansara, and Saanvi Shah as part of the identifying outliers and unsupervised learning subteams of the Hack the GLOBE! project in the NASA SEES internship program."
      ],
      "metadata": {
        "id": "ZqKVMRuoRkNm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4B16-nx0WZrv"
      },
      "outputs": [],
      "source": [
        "# Importing KaggleHub and setting up the environment\n",
        "# Authenticating Kaggle API\n",
        "\n",
        "import kagglehub\n",
        "import os\n",
        "\n",
        "os.environ['KAGGLE_USERNAME'] = 'your_username'\n",
        "os.environ['KAGGLE_KEY'] = 'your_api_key'\n",
        "\n",
        "from kaggle import api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HDpJAbEWZrw"
      },
      "outputs": [],
      "source": [
        "# Importing Hack the GLOBE! data source\n",
        "\n",
        "hack_the_globe_path = kagglehub.competition_download('hack-the-globe')\n",
        "\n",
        "print('Data source import complete.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDWRg8tZWZrw"
      },
      "source": [
        "# Initialize your environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-06-20T21:09:08.149686Z",
          "iopub.status.busy": "2025-06-20T21:09:08.14941Z",
          "iopub.status.idle": "2025-06-20T21:09:08.154049Z",
          "shell.execute_reply": "2025-06-20T21:09:08.153122Z",
          "shell.execute_reply.started": "2025-06-20T21:09:08.149666Z"
        },
        "id": "_x4nERLtWZrx",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import os\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import pyarrow\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15h43cRDWZrx"
      },
      "source": [
        "# Load the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-20T21:10:58.971205Z",
          "iopub.status.busy": "2025-06-20T21:10:58.970483Z",
          "iopub.status.idle": "2025-06-20T21:11:02.887839Z",
          "shell.execute_reply": "2025-06-20T21:11:02.887008Z",
          "shell.execute_reply.started": "2025-06-20T21:10:58.971162Z"
        },
        "id": "ZP1egGhAWZrx",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "#     for filename in filenames:\n",
        "#         print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
        "\n",
        "parquet_file_path = os.path.join(hack_the_globe_path, 'mv_surface_temperatures_wide.parquet')\n",
        "df = pd.read_parquet(parquet_file_path)\n",
        "display(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cIbiSvSWZry"
      },
      "source": [
        "# Data Profiling\n",
        "Utilized `df.info()` to gain a general sense for the DataFrame. Came to the following conclusions:\n",
        "\n",
        "*   64 columns, 716031 rows\n",
        "*   2 columns (`submission_access_code_id`, `site_nickname`) only contain null values\n",
        "*   Some data has only been collected more recently (`site_true_latitude`, `site_true_longitude`, `site_true_elevation`, `site_true_point` with only 84 non-null values)\n",
        "*   Dtypes primarily used include string, Int64, float64 in order of prevalence\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llA1fdZdWZry",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Displaying the DataFrame information\n",
        "print(df.info())\n",
        "# Displaying the shape of the DataFrame\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ex2y5aRn4KuH"
      },
      "outputs": [],
      "source": [
        "# Displaying number of null values in each column from greatest to least\n",
        "print(df.isnull().sum().sort_values(ascending=False))\n",
        "# Displaying proportion of null values in each column from greatest to least\n",
        "print(df.isna().mean().sort_values(ascending=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWaNx-Qd4KuH"
      },
      "source": [
        "The two columns with pure null values won't help in data analysis, and thus can be removed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PueJrcgD4KuH"
      },
      "outputs": [],
      "source": [
        "# Remove columns with only null values\n",
        "df = df.drop(columns=['submission_access_code_id', 'site_nickname'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5UFYGEX4KuI"
      },
      "outputs": [],
      "source": [
        "import folium\n",
        "from folium.plugins import MarkerCluster\n",
        "\n",
        "# Filter rows with valid submission coordinates\n",
        "df_valid = df[['submission_latitude', 'submission_longitude']].dropna()\n",
        "\n",
        "# Center map at the mean of valid coordinates\n",
        "map_center = [\n",
        "    df_valid['submission_latitude'].mean(),\n",
        "    df_valid['submission_longitude'].mean()\n",
        "]\n",
        "\n",
        "m = folium.Map(location=map_center, zoom_start=2)\n",
        "marker_cluster = MarkerCluster().add_to(m)\n",
        "\n",
        "for _, row in df_valid.iterrows():\n",
        "    folium.Marker(\n",
        "        location=[row['submission_latitude'], row['submission_longitude']]\n",
        "    ).add_to(marker_cluster)\n",
        "\n",
        "m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4A65sQDS4KuI"
      },
      "source": [
        "# Location Outliers\n",
        "Key observation: multiple sets of clearly invalid coordinates, including cluster of 692 north of Alaska, cluster of 27 north of Russia, and a clusters of 9 and 3 near the coordinates of (0,0). Next steps include investigating the outlier points based on coordinates, as well as differentiating between the site coordinates and submission coordinates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "ruby"
        },
        "id": "ByTZHeYm4KuI"
      },
      "outputs": [],
      "source": [
        "# Define latitude and longitude thresholds for likely and impossible coordinates\n",
        "likely_lat_min, likely_lat_max = -60, 85    # Most land-based submissions\n",
        "likely_lon_min, likely_lon_max = -180, 180  # Valid longitude range\n",
        "\n",
        "# Impossible coordinates: outside valid lat/lon range\n",
        "impossible_coords = (\n",
        "    (df['submission_latitude'] < -90) | (df['submission_latitude'] > 90) |\n",
        "    (df['submission_longitude'] < -180) | (df['submission_longitude'] > 180)\n",
        ")\n",
        "\n",
        "# Unlikely but possible: outside likely land-based range but still valid\n",
        "unlikely_coords = (\n",
        "    ((df['submission_latitude'] < likely_lat_min) | (df['submission_latitude'] > likely_lat_max)) &\n",
        "    (df['submission_latitude'].notna())\n",
        ")\n",
        "\n",
        "# Points close to (0,0)\n",
        "zero_point_coords = (\n",
        "    df['submission_latitude'].between(-1, 1) &\n",
        "    df['submission_longitude'].between(-1, 1)\n",
        ")\n",
        "\n",
        "# Combine all criteria\n",
        "flagged_coords = df[impossible_coords | unlikely_coords | zero_point_coords]\n",
        "\n",
        "# Show summary\n",
        "print(f\"Impossible coords: {impossible_coords.sum()}\")\n",
        "print(f\"Unlikely coords: {unlikely_coords.sum()}\")\n",
        "print(f\"Near (0,0): {zero_point_coords.sum()}\")\n",
        "print(f\"Total flagged: {len(flagged_coords)}\")\n",
        "display(flagged_coords[['submission_latitude', 'submission_longitude']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GpZ0atF4KuI"
      },
      "source": [
        "The results match our earlier observations of the map. Many seem to be in clusters and likely are from the same userid or organizationid."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Osqu90Cj4KuI"
      },
      "outputs": [],
      "source": [
        "# Get unique organizationid values from flagged_coords\n",
        "org_ids_flagged = flagged_coords['organizationid'].unique()\n",
        "print(org_ids_flagged)\n",
        "print(flagged_coords.value_counts('organizationid'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3p4adh0Z4KuI"
      },
      "source": [
        "Used the GLOBE API (https://api.globe.gov/search/swagger-ui.html#/v-1-controller/findByProtocolAndMeasuredDateAndOAndOrganizationIdUsingGET) to determine the identities of the organizations:\n",
        "* 78523475: Iksal 'c' Primary School (Israel)\n",
        "  * Responsible for cluster of 692 north of Alaska\n",
        "* 6512608: NASA Langley Research Center GLOBE v-School (United States)\n",
        "  * Responsible for cluster of 9 at (0,0)\n",
        "* 106363801: Queen Elizabeth College (Mauritius)\n",
        "  * Responsible for 2 points near (0,0)\n",
        "* 58728215: Federal Government Girls College, Calabar (Nigeria)\n",
        "  * Responsible for 1 point near (0,0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OB2D7TLtHzcm"
      },
      "outputs": [],
      "source": [
        "org_id = 78523475 # Iksal 'c' Primary School organizationid\n",
        "df_filtered = df[\n",
        "    (df['organizationid'] == org_id) &\n",
        "    (df['submission_latitude'].notna()) &\n",
        "    (df['submission_longitude'].notna())\n",
        "]\n",
        "\n",
        "# Get average location to center the map\n",
        "center_lat = df_filtered['submission_latitude'].mean()\n",
        "center_lon = df_filtered['submission_longitude'].mean()\n",
        "\n",
        "# Create the Folium map\n",
        "m = folium.Map(location=[center_lat, center_lon], zoom_start=4)\n",
        "\n",
        "marker_cluster = MarkerCluster().add_to(m)\n",
        "\n",
        "# Add markers\n",
        "for _, row in df_filtered.iterrows():\n",
        "    folium.Marker(\n",
        "        location=[row['submission_latitude'], row['submission_longitude']],\n",
        "        popup=f\"Surface Temp: {row['sample_surface_temperature_c']}\",\n",
        "        tooltip=row.get('site_id', 'Site')\n",
        "    ).add_to(marker_cluster)\n",
        "\n",
        "# Display map\n",
        "m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNtl_cS94KuJ"
      },
      "source": [
        "Hypothesis of 692 points coming from Iksal 'c' Primary School confirmed."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Coordinate Uncertainty"
      ],
      "metadata": {
        "id": "Mthj9pvObG2S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jM3_pjlA4KuJ"
      },
      "outputs": [],
      "source": [
        "import geopandas as gpd\n",
        "import contextily as ctx\n",
        "\n",
        "# Filter rows with only site coordinates\n",
        "df_filtered = df[\n",
        "    df['site_latitude'].notna() &\n",
        "    df['site_longitude'].notna() &\n",
        "    df['submission_latitude'].isna() &\n",
        "    df['submission_longitude'].isna() &\n",
        "    df['site_latitude'].between(-90, 90) &\n",
        "    df['site_longitude'].between(-180, 180)\n",
        "]\n",
        "\n",
        "# Convert to GeoDataFrame\n",
        "gdf = gpd.GeoDataFrame(\n",
        "    df_filtered,\n",
        "    geometry=gpd.points_from_xy(df_filtered['site_longitude'], df_filtered['site_latitude']),\n",
        "    crs=\"EPSG:4326\"\n",
        ")\n",
        "\n",
        "# Reproject to Web Mercator\n",
        "gdf = gdf.to_crs(epsg=3857)\n",
        "\n",
        "# Plot\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "gdf.plot(ax=ax, markersize=10, alpha=0.6, color='crimson', label=\"Site Only\")\n",
        "# Changed the basemap provider from Stamen.TerrainBackground to OpenStreetMap.Mapnik\n",
        "ctx.add_basemap(ax, source=ctx.providers.OpenStreetMap.Mapnik)\n",
        "ax.set_axis_off()\n",
        "plt.title(\"Site Coordinates Without Submission Coordinates\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARKzGZys4KuJ"
      },
      "source": [
        "Many rows seem to have site coordinates but not submission coordinates. For the rows that do have both, we want to check if any have differences or errors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_M-Bww8q-Hj"
      },
      "outputs": [],
      "source": [
        "df_geo = df.dropna(subset=[\n",
        "    'site_latitude', 'site_longitude',\n",
        "    'submission_latitude', 'submission_longitude'\n",
        "])\n",
        "\n",
        "# Define a small tolerance to handle floating point precision\n",
        "tolerance = 100\n",
        "\n",
        "# Find rows where lat/lon values differ more than the tolerance\n",
        "mismatches = df[\n",
        "    ((df['site_latitude'] - df['submission_latitude']).abs() > tolerance) |\n",
        "    ((df['site_longitude'] - df['submission_longitude']).abs() > tolerance)\n",
        "]\n",
        "\n",
        "# Output the count and optionally preview\n",
        "print(f\"Number of mismatched coordinates: {len(mismatches)}\")\n",
        "print(mismatches[['organizationid','site_latitude', 'site_longitude', 'submission_latitude', 'submission_longitude']].value_counts('organizationid'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "he9U2cZp4KuJ"
      },
      "source": [
        "organizationid 394556 has 27 extremely mismatched coordinates (viewed on the Folium map earlier). After plugging into the aforementioned GLOBE API, it can be determined that these points originated from the University of Toledo (United States)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvYyGuS8tV_1"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "from folium.plugins import HeatMap\n",
        "\n",
        "df_geo = df[['submission_latitude', 'submission_longitude', 'site_elevation', 'sample_surface_temperature_c']].dropna()\n",
        "\n",
        "heat_data = [\n",
        "    [row['submission_latitude'], row['submission_longitude'], row['sample_surface_temperature_c']]\n",
        "    for _, row in df_geo.iterrows()\n",
        "]\n",
        "\n",
        "map_center = [df_geo['submission_latitude'].mean(), df_geo['submission_longitude'].mean()]\n",
        "m = folium.Map(location=map_center, zoom_start=2)\n",
        "\n",
        "HeatMap(heat_data, min_opacity=0.3, radius=8, blur=4).add_to(m)\n",
        "\n",
        "m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jq9YlTyJ4KuJ"
      },
      "source": [
        "The heatmap above shows where large amounts of data have been entered from. Notable locations include the University of Toledo (United States), Iksal 'c' Primary School (Israel), and National Taiwan University (Taiwan). To see if an error was made when entering coordinates for Iksal 'c' Primary School, we can list the coordinates that weren't part of the batch of 692 from earlier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6R_w4V3NRl07"
      },
      "outputs": [],
      "source": [
        "from geopy.distance import geodesic\n",
        "\n",
        "# Filter by organizationid\n",
        "df_filtered = df[\n",
        "    (df['organizationid'] == 78523475) &\n",
        "    (df['submission_latitude'].notna()) &\n",
        "    (df['submission_longitude'].notna())\n",
        "]\n",
        "\n",
        "# Define Israel center\n",
        "israel_coords = (31.0461, 34.8516)\n",
        "\n",
        "# Define distance threshold in miles\n",
        "distance_limit_miles = 500\n",
        "\n",
        "# Function to compute distance from Israel center\n",
        "def is_within_radius(row):\n",
        "    point = (row['submission_latitude'], row['submission_longitude'])\n",
        "    return geodesic(point, israel_coords).miles <= distance_limit_miles\n",
        "\n",
        "# Apply the distance filter\n",
        "df_near_israel = df_filtered[df_filtered.apply(is_within_radius, axis=1)]\n",
        "\n",
        "# Show result\n",
        "print(df_near_israel.value_counts('organizationid'))\n",
        "print(df_near_israel.value_counts('userid'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qLEIVts4KuJ"
      },
      "source": [
        "This confirms our suspicions that the data in the batch of 692 might have been submitted with the same submission coordinates in error. In addition, it appears that there is only one userid entering the data for the non-faulty values from Iksal 'c' Primary School, implying that a teacher might be entering data for students. Next, we can search for coordinates with exorbitantly high temperature, where users might have incorrectly inputted the temperature in Fahreinheit instead of Celsius."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Temperature Outliers"
      ],
      "metadata": {
        "id": "KVrwdZ4kbM9u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_IqlLiFu4KuJ"
      },
      "outputs": [],
      "source": [
        "# Find rows with surface temperatures higher than 60°C\n",
        "high_temp_coords = df[df['sample_surface_temperature_c'] > 60]\n",
        "\n",
        "# Display summary and preview\n",
        "print(f\"Number of rows with surface temperature > 60°C: {len(high_temp_coords)}\")\n",
        "display(high_temp_coords[['site_latitude', 'site_longitude', 'sample_surface_temperature_c', 'organizationid', 'userid']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZSAVHLa4KuJ"
      },
      "source": [
        "# Interpretable Flagging\n",
        "Now we can combine this new temperature based information with the coordinate information to create boolean flagging columns for unlikely temperature, impossible coordinates, unlikely coordinates, coordinates near (0,0), and mismatched site and submission coordinates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKAzJKFp4KuJ"
      },
      "outputs": [],
      "source": [
        "# Add boolean flag columns to df for outlier temperatures and coordinates\n",
        "\n",
        "# Outlier temperature: surface temperature > 60°C (possible Fahrenheit entry or error)\n",
        "df['is_temp_outlier'] = df['sample_surface_temperature_c'] > 60\n",
        "\n",
        "# Outlier coordinates: use previously defined impossible_coords, unlikely_coords, zero_point_coords\n",
        "df['is_impossible_coord'] = impossible_coords\n",
        "df['is_unlikely_coord'] = unlikely_coords\n",
        "df['is_zero_point_coord'] = zero_point_coords\n",
        "\n",
        "# Add a boolean flag for mismatched site and submission coordinates\n",
        "df['is_mismatched_coord'] = (\n",
        "    ((df['site_latitude'] - df['submission_latitude']).abs() > tolerance) |\n",
        "    ((df['site_longitude'] - df['submission_longitude']).abs() > tolerance)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFDmNloP4KuK"
      },
      "source": [
        "In addition, we'll add two columns: one summing the number of flags a row has, and the other a boolean value to track whether the row has more than 3 flags."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUmQM5xc4KuK"
      },
      "outputs": [],
      "source": [
        "# Add a column that sums the number of flags for each row\n",
        "flag_columns = [\n",
        "    'is_temp_outlier',\n",
        "    'is_impossible_coord',\n",
        "    'is_unlikely_coord',\n",
        "    'is_zero_point_coord',\n",
        "    'is_mismatched_coord'\n",
        "]\n",
        "df['num_flags'] = df[flag_columns].sum(axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PiqnehB4KuK"
      },
      "source": [
        "Now we can check how many rows have flags."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rk4G3s5T4KuK"
      },
      "outputs": [],
      "source": [
        "# Count rows with at least one flag\n",
        "num_with_flags = (df['num_flags'] > 0).sum()\n",
        "print(f\"Rows with at least one flag: {num_with_flags}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KiFoM-hn4KuK"
      },
      "outputs": [],
      "source": [
        "# Create a dataset without any flagged rows (i.e., rows where num_flags == 0)\n",
        "df_clean = df[df['num_flags'] == 0].copy()\n",
        "print(f\"Shape of clean dataset: {df_clean.shape}\")\n",
        "display(df_clean.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVDPz2Kd4KuK"
      },
      "source": [
        "# Unsupervised Learning\n",
        "Now that we have sorted out easily identifiable outliers, we can use unsupervised learning methods like K-Means, DBSCAN, and GMM to potentially find new outliers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSYKV8984KuK"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Select numeric columns for clustering (e.g., latitude, longitude, temperature)\n",
        "features = ['site_latitude', 'site_longitude', 'sample_surface_temperature_c']\n",
        "df_kmeans = df_clean.dropna(subset=features).copy()\n",
        "\n",
        "X = df_kmeans[features].values\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Fit K-Means (choose k=5 as an example, adjust as needed)\n",
        "kmeans = KMeans(n_clusters=5, random_state=42, n_init=10)\n",
        "df_kmeans['kmeans_label'] = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "# Show cluster counts\n",
        "print(df_kmeans['kmeans_label'].value_counts())\n",
        "df_kmeans.head()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "scatter = plt.scatter(\n",
        "    df_kmeans['site_longitude'],\n",
        "    df_kmeans['site_latitude'],\n",
        "    c=df_kmeans['kmeans_label'],\n",
        "    cmap='tab10',\n",
        "    alpha=0.6\n",
        ")\n",
        "plt.xlabel('Longitude')\n",
        "plt.ylabel('Latitude')\n",
        "plt.title('K-Means Clusters (k=5)')\n",
        "plt.colorbar(scatter, label='Cluster Label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0egYXEe4KuK"
      },
      "source": [
        "K-Means seems to somewhat align with geographical groupings, which makes sense given the data we fed it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZhGWtMwR4KuK"
      },
      "outputs": [],
      "source": [
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "gmm = GaussianMixture(n_components=5, random_state=42)\n",
        "gmm.fit(X_gmm)\n",
        "\n",
        "# Select features for GMM clustering\n",
        "features = ['site_latitude', 'site_longitude', 'sample_surface_temperature_c']\n",
        "df_gmm = df_clean.dropna(subset=features).copy()\n",
        "X_gmm = df_gmm[features].values\n",
        "\n",
        "# Predict GMM cluster labels\n",
        "df_gmm['gmm_label'] = gmm.predict(X_gmm)\n",
        "\n",
        "# Show cluster counts and preview\n",
        "print(df_gmm['gmm_label'].value_counts())\n",
        "display(df_gmm.head())\n",
        "\n",
        "# Optional: visualize clusters\n",
        "plt.figure(figsize=(10, 6))\n",
        "scatter = plt.scatter(\n",
        "    df_gmm['site_longitude'],\n",
        "    df_gmm['site_latitude'],\n",
        "    c=df_gmm['gmm_label'],\n",
        "    cmap='tab10',\n",
        "    alpha=0.6\n",
        ")\n",
        "plt.xlabel('Longitude')\n",
        "plt.ylabel('Latitude')\n",
        "plt.title('GMM Clusters (n_components=5)')\n",
        "plt.colorbar(scatter, label='GMM Cluster Label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WnGdSzJZ4KuP"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Select numeric columns for PCA (same as clustering)\n",
        "features = ['site_latitude', 'site_longitude', 'sample_surface_temperature_c']\n",
        "df_pca = df_clean.dropna(subset=features).copy()\n",
        "X_pca = df_pca[features].values\n",
        "\n",
        "# Standardize features\n",
        "X_pca_scaled = scaler.transform(X_pca)\n",
        "\n",
        "# Fit PCA\n",
        "pca = PCA(n_components=2)\n",
        "principal_components = pca.fit_transform(X_pca_scaled)\n",
        "\n",
        "# Add principal components to DataFrame\n",
        "df_pca['PC1'] = principal_components[:, 0]\n",
        "df_pca['PC2'] = principal_components[:, 1]\n",
        "\n",
        "# Plot the first two principal components\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(df_pca['PC1'], df_pca['PC2'], alpha=0.5, s=10)\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.title('PCA of Clean Data')\n",
        "plt.show()\n",
        "\n",
        "# Explained variance ratio\n",
        "print(\"Explained variance ratio:\", pca.explained_variance_ratio_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLUkrGxM4KuP"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "\n",
        "# Use the same features as before\n",
        "features = ['site_latitude', 'site_longitude', 'sample_surface_temperature_c']\n",
        "df_unsup = df_clean.dropna(subset=features).copy()\n",
        "X_unsup = df_unsup[features].values\n",
        "\n",
        "# Isolation Forest\n",
        "iso_forest = IsolationForest(contamination=0.01, random_state=42)\n",
        "df_unsup['iso_outlier'] = iso_forest.fit_predict(X_unsup) == -1\n",
        "\n",
        "# Local Outlier Factor\n",
        "lof = LocalOutlierFactor(n_neighbors=20, contamination=0.01)\n",
        "df_unsup['lof_outlier'] = lof.fit_predict(X_unsup) == -1\n",
        "\n",
        "# Show counts of detected outliers\n",
        "print(\"Isolation Forest outliers:\", df_unsup['iso_outlier'].sum())\n",
        "print(\"Local Outlier Factor outliers:\", df_unsup['lof_outlier'].sum())\n",
        "\n",
        "# Optionally, preview some outliers\n",
        "display(df_unsup[df_unsup['iso_outlier'] | df_unsup['lof_outlier']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Dataset Without Outliers"
      ],
      "metadata": {
        "id": "w3vz6i29bcq7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PnB7IRd4KuP"
      },
      "outputs": [],
      "source": [
        "# Exclude rows detected as outliers by either Isolation Forest or Local Outlier Factor\n",
        "final_df = df_clean.drop(df_unsup[df_unsup['iso_outlier'] | df_unsup['lof_outlier']].index)\n",
        "print(f\"Final dataset shape (excluding unsupervised outliers): {final_df.shape}\")\n",
        "display(final_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHoyVmNZ4KuP"
      },
      "source": [
        "While this final dataframe obviously isn't perfect, it lets users perform data analysis without egregious outliers or faulty data."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "databundleVersionId": 12777374,
          "sourceId": 104499,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 31040,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
